{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9544b4-3b33-4895-8be9-e2101501966e",
   "metadata": {},
   "source": [
    "# Boilerplate (imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b366b-9dfc-4f57-83d4-6da99d8d3c32",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import cobra\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "import os.path\n",
    "import gurobipy # make sure some solver backend is available for iMAT/FBA/MoMA\n",
    "from projection_methods import MoMAWrapper, FbaProjection, FbaProjectionLowMidConfidence, FbaProjectionHighMidConfidence, FBAWrapper, IMATWrapper\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up gurobi or other optimizer license file if needed\n",
    "# os.environ['GRB_LICENSE_FILE'] = \"/path/to/your/gurobi.lic\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84831959106b682d"
  },
  {
   "cell_type": "markdown",
   "id": "83f94790-6354-488e-ada2-af6edb7efa58",
   "metadata": {},
   "source": [
    "# Test with iid noise to steady-state data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515613ed-c1db-43e6-a4a4-e56a850a52e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a483e6e-ca9e-4efe-ae67-006e339b79af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "reaction_size_cutoff = 20000 # > 10600 for all models in model_organism_* variables\n",
    "n_samples_per_graph = 10\n",
    "base_noise_power = 1\n",
    "base_frac_known_reactions = 0.1\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "models = list()\n",
    "As = list()\n",
    "ss_bases = list()\n",
    "ss_fluxes = list()\n",
    "perturbed_fluxes = list()\n",
    "names = list()\n",
    "masks = list()\n",
    "\n",
    "data_dir = 'synthetic_data_experiment_files/data' # make sure this has the models specified below, in sbml format. \n",
    "caching_dir = 'synthetic_data_experiment_files/caching'\n",
    "export_path = 'synthetic_data_experiment_files/outputs'\n",
    "\n",
    "model_organism_model_names = ['e_coli_core', 'iML1515', 'iND750', 'iMM1415', 'RECON1', 'Recon3D']\n",
    "model_organism_organisms = ['e_coli_core', 'e_coli_K_12', 'yeast', 'mouse', 'human_1', 'human_3d']\n",
    "model_name_to_organism = {k: v for k, v in zip(model_organism_model_names, model_organism_organisms)}\n",
    "# ordered_organisms = []\n",
    "\n",
    "for i, model_filename in enumerate(os.listdir(data_dir)):\n",
    "    name = model_filename.split('.')[0]\n",
    "    if name not in model_organism_model_names:\n",
    "        continue\n",
    "    model = cobra.io.read_sbml_model(os.path.join(data_dir, model_filename))\n",
    "    if len(model.reactions) > reaction_size_cutoff:\n",
    "        continue    \n",
    "    models.append(model)\n",
    "    if os.path.exists(os.path.join(caching_dir, name + \"_cached_A.npy\")):\n",
    "        print(i, name, \"(cached)\")\n",
    "        A = np.load(os.path.join(caching_dir, name + \"_cached_A.npy\"))\n",
    "        basis = np.load(os.path.join(caching_dir, name + \"_cached_basis.npy\")) \n",
    "    else:\n",
    "        print(i, name)\n",
    "        A = cobra.util.create_stoichiometric_matrix(model)\n",
    "        basis = scipy.linalg.null_space(A) # a reactions X kernel-dimension array\n",
    "        np.save(os.path.join(caching_dir, name + \"_cached_A\"), A)\n",
    "        np.save(os.path.join(caching_dir, name + \"_cached_basis\"), basis) \n",
    "        \n",
    "    print(\"Model shape: {}\".format(A.shape))\n",
    "    As.append(A)\n",
    "    names.append(model_filename.split(\".\")[0])\n",
    "\n",
    "    # A = A.astype(float)\n",
    "\n",
    "    print(\"ss basis shape:\", basis.shape)\n",
    "    \n",
    "    ss_bases.append(basis)\n",
    "    \n",
    "    coefficients = np.random.random(size=(basis.shape[1], n_samples_per_graph))\n",
    "    steady_states = (basis @ coefficients).transpose() # a samples X reactions array.\n",
    "    ss_fluxes.append(steady_states)\n",
    "    \n",
    "    known_indices = np.array(sorted(np.random.choice(np.array(list(range(A.shape[1]))), size=math.ceil(base_frac_known_reactions * A.shape[1]), replace=False)))\n",
    "    mask = np.zeros(A.shape[1],dtype=bool)\n",
    "    mask[known_indices] = True    \n",
    "\n",
    "    noised_steady_states = [ss * np.where(mask, 1, (1 + base_noise_power * 2 * (np.random.random(size=ss.shape) - 0.5))) for ss in steady_states]\n",
    "    \n",
    "    # now only\n",
    "    \n",
    "    noised_steady_states = np.array(noised_steady_states)\n",
    "    perturbed_fluxes.append(noised_steady_states)\n",
    "    masks.append(mask)\n",
    "    \n",
    "    \n",
    "ys = [torch.tensor(y.astype(np.float64)) for y in ss_fluxes]\n",
    "Xs = [torch.tensor(X.astype(np.float64)) for X in perturbed_fluxes]\n",
    "\n",
    "n_graphs = len(As)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208e206-1f95-421e-9d1a-8e3d49f783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    # Open up all exchanges and blocked reactions with high bounds\n",
    "    for r in model.reactions:\n",
    "        bounds = [r.bounds[0], r.bounds[1]]\n",
    "        if bounds[0] < 0:\n",
    "            bounds[0] = -1000\n",
    "        if bounds[1] > 0:\n",
    "            bounds[1] = 1000\n",
    "        # if bounds[1] == 1000:\n",
    "        #     bounds[1] = 10\n",
    "        # if bounds[0] == -1000:\n",
    "        #     bounds[0] = -10\n",
    "        if bounds == (0, 0):\n",
    "            bounds = -1000, 1000\n",
    "        # if \"ex\" in r.id.lower(): \n",
    "        #     bounds = (-10, 10)\n",
    "        r.bounds = bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e3976ebcf20ad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate approximate bounds to be used for FBA and iterative projection versions\n",
    "ls = []\n",
    "us = []\n",
    "epsilon = 1e-5\n",
    "for model_index, model, X, Y, mask in zip(list(range(len(models))), models, Xs, ys, masks):\n",
    "    print(model_index)\n",
    "    # print(model_index, len(model.reactions), len(models), X.shape, Y.shape, mask.shape)\n",
    "    l = np.zeros(shape=(X.shape[0], X.shape[1]))\n",
    "    u = np.zeros(shape=(X.shape[0], X.shape[1]))\n",
    "    for i, sample in enumerate(Y):\n",
    "        # Change bounds to the gap that was possible during the noise generation if unknown, and roughly the measured values for measured indices\n",
    "        \n",
    "        sign = torch.sign(sample)\n",
    "        l[i, :] = (1 - base_noise_power * sign * ~mask) * sample - epsilon  \n",
    "        u[i, :] = (1 + base_noise_power * sign * ~mask) * sample + epsilon  \n",
    "        \n",
    "    l = torch.tensor(l, dtype=torch.float, device=device)\n",
    "    u = torch.tensor(u, dtype=torch.float, device=device)\n",
    "    ls.append(l)\n",
    "    us.append(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0543e-ad6a-472d-aced-c3e486d6e5d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply projection and FBA on zeroed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52e869-2d55-42d9-bb25-3cfb63433910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "acond=1e-3\n",
    "rcond=1e-3\n",
    "    \n",
    "methods = [\n",
    "          FbaProjection, \n",
    "          FbaProjectionLowMidConfidence,\n",
    "          FbaProjectionHighMidConfidence,\n",
    "          FBAWrapper,\n",
    "          IMATWrapper,\n",
    "          MoMAWrapper\n",
    "            ]\n",
    "method_names = [m.__repr__(None) for m in methods]\n",
    "\n",
    "containers = [[] for method in methods]\n",
    "\n",
    "\n",
    "for i, model, A, X, mask, l, u, basis in zip(range(len(models)), models, As, Xs, masks, ls, us, ss_bases):\n",
    "    print(i)\n",
    "\n",
    "    obj_coefs = {rxn.id: rxn.objective_coefficient for rxn in model.reactions if rxn.objective_coefficient != 0}\n",
    "    print(obj_coefs)\n",
    "    print([r.id for r in model.reactions if 'biomass' in r.id.lower()])\n",
    "    if len(obj_coefs) == 0:\n",
    "        growth_related_reactions = [r.id for r in model.reactions if 'biomass' in r.id.lower()]\n",
    "        assert len(growth_related_reactions) == 1\n",
    "        obj_coefs = {growth_related_reactions[0]: 1}\n",
    "    assert len(obj_coefs) == 1 and all([v == 1 for k, v in obj_coefs.items()])\n",
    "    objective_reaction_ids = obj_coefs.popitem()[0]\n",
    "\n",
    "    \n",
    "    with model:\n",
    "        # obj = linear_reaction_coefficients(model)\n",
    "        # assert len(obj) == 1\n",
    "        # objective_id = obj.popitem()[0].id\n",
    "        unknown_indices = [q for q in range(len(mask)) if ~(mask[q])]\n",
    "        measured_indices = [q for q in range(len(mask)) if mask[q]]\n",
    "        for method, container in zip(methods, containers): \n",
    "            proj = method(stoichiometric_matrix=A, model=model, unknown_indices=unknown_indices, measured_indices=measured_indices, \n",
    "                          steady_state_basis_matrix=basis, objective_id=objective_reaction_ids,\n",
    "                          l_bounds=l, u_bounds=u, device=device,\n",
    "                          dtype=torch.float)\n",
    "            y_pred = proj.forward(X.to(dtype=torch.float, device=device), l_bounds=l, u_bounds=u)\n",
    "            container.append(y_pred)\n",
    "            del proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00a11a563aa7b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "for i, y in enumerate(ys):\n",
    "    print(i)\n",
    "    for method_name, container in zip(method_names, containers):\n",
    "        for metric in ['spearmanr', 'l2']:\n",
    "            if metric == 'l2':\n",
    "                continue\n",
    "            corr_func = stats.spearmanr if metric == 'spearmanr' else lambda a, b, nan_policy='omit': (-scipy.linalg.norm((a - b).values, axis=0), 0)\n",
    "            for masking in ['all', 'known', 'unknown']:\n",
    "                if masking == 'all':\n",
    "                    continue\n",
    "                    # mask = torch.ones_like(y[0], dtype=torch.bool)\n",
    "                elif masking == 'known':\n",
    "                    mask = torch.tensor(masks[i], dtype=torch.bool)\n",
    "                else:\n",
    "                    mask = ~torch.tensor(masks[i], dtype=torch.bool)\n",
    "                for axis in ['per sample', 'per reaction']:\n",
    "                    data = y[:, mask]\n",
    "                    preds = container[i][:, mask]\n",
    "                    if axis == 'per sample':\n",
    "                        # continue\n",
    "                        data = data.transpose(0, 1)\n",
    "                        preds = preds.transpose(0, 1)\n",
    "                        # assert sizes match and make them into dfs\n",
    "                    assert data.shape == preds.shape\n",
    "                    data = pd.DataFrame(data.cpu().numpy())\n",
    "                    preds = pd.DataFrame(preds.cpu().numpy())\n",
    "                    corrs, _, full_corr, _ = util.run_correlation_tests(data, preds, corr_func=corr_func, parallel=False)\n",
    "                    # function is run per columns, transpose if doing per sample.\n",
    "                    if axis == 'per sample':\n",
    "                        assert len(corrs) == y[:, mask].shape[0]\n",
    "                    else:\n",
    "                        assert len(corrs) == y[:, mask].shape[1]\n",
    "                    for val in corrs.values():\n",
    "                        entries.append({'model': model_name_to_organism[models[i].id], 'method': method_name, 'metric': metric, 'axis': axis, 'masking': masking, 'value': val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff38c66aa7f59d4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert entries to a datafram\n",
    "results = pd.DataFrame.from_records(entries)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd625a18c80516",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "filtered = results.loc[(results['metric'] == 'spearmanr') &  (results['axis'] == 'per reaction') & (results['masking'] == 'unknown')]\n",
    "\n",
    "filtered['method'] = filtered['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\").str.replace(\"Reference Values\", \"Mid-bound Benchmark\")\n",
    "filtered['method'] = pd.Categorical(filtered['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                ])\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.catplot(data=filtered.sort_values(by=['method', 'model']), hue=\"method\", x='model', y=\"value\",\n",
    "                          height=8,\n",
    "               aspect=1.7,\n",
    "               kind='bar')\n",
    "filename =  \"exact_rxn_unknown.png\"\n",
    "plt.gcf().savefig(os.path.join(export_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9544e-1344-4908-8be7-05582a6e5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.set(style=\"darkgrid\", font_scale=2)\n",
    "filtered = results.loc[(results['metric'] == 'spearmanr') & (results['masking'] == 'unknown')]\n",
    "filtered = filtered.loc[filtered['model'] == 'human_1']\n",
    "filtered['method'] = filtered['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\").str.replace(\"Reference Values\", \"Mid-bound Benchmark\")\n",
    "filtered['method'] = pd.Categorical(filtered['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                ])\n",
    "\n",
    "\n",
    "g=sns.catplot(data=filtered.sort_values(by=['method', 'model']), hue=\"method\", x='axis', y=\"value\",\n",
    "               height=8,\n",
    "               aspect=1.7,\n",
    "               kind='bar'\n",
    "           )\n",
    "plt.ylabel(\"Spearman Correlation\")\n",
    "g._legend.set_title(\"Method\")\n",
    "g._legend.set_bbox_to_anchor((1.12, 0.7))\n",
    "plt.tight_layout()\n",
    "\n",
    "filename =  \"exact_rxn_unknown.png\"\n",
    "plt.gcf().savefig(os.path.join(export_path, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf9d34-dfa8-4a95-88e5-276157eb4327",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check dependences of performance on fraction of unknown reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94764dfb-d839-4e69-a1b9-9e84aa0f7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "          FbaProjection, \n",
    "          FbaProjectionLowMidConfidence,\n",
    "          FbaProjectionHighMidConfidence,\n",
    "          FBAWrapper,\n",
    "          IMATWrapper,\n",
    "          MoMAWrapper\n",
    "            ]\n",
    "method_names = [m.__repr__(None) for m in methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a61a3-f537-48a3-aedc-20bf3dc8234d",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "known_reactions_steps = list(np.linspace(start=0.05, stop=0.5, num=10, endpoint=False))\n",
    "\n",
    "acond=1e-2\n",
    "rcond=1e-2\n",
    "\n",
    "known_varying_entries = list()\n",
    "# known_varying_entries = [e for e in known_varying_entries if e['method'] != 'FBAproHighMid']\n",
    "for i, known_frac in enumerate(known_reactions_steps):\n",
    "    print(\"known frac: {}\".format(known_reactions_steps[i]))\n",
    "    ss_fluxes = list()\n",
    "    perturbed_fluxes = list()\n",
    "    names = list()\n",
    "    masks = list()\n",
    "\n",
    "    coefficients = [np.random.random(size=(basis.shape[1], n_samples_per_graph)) for basis in ss_bases]\n",
    "    steady_states = [(basis @ coef).transpose() for basis, coef in zip(ss_bases, coefficients)]     \n",
    "    known_indices_list = [sorted(np.random.choice(np.array(list(range(nss.shape[1]))), size=math.ceil(known_frac * nss.shape[1]), \n",
    "                                      replace=False))\n",
    "                         for nss in steady_states]\n",
    "    masks = list()\n",
    "    noised_steady_states = list()\n",
    "    for ss, idxs in zip(steady_states, known_indices_list):\n",
    "        mask = np.zeros(ss.shape[1],dtype=bool)\n",
    "        mask[idxs] = True\n",
    "        # print(\"mask sum:\", sum(mask))\n",
    "        masks.append(mask)\n",
    "        noised = list()\n",
    "        # print(\"ss shape:\", ss.shape)\n",
    "        for s in ss:\n",
    "            # print(\"s shape:\", s.shape)\n",
    "            ns = s * np.where(mask, 1, (1 + base_noise_power * 2 * (np.random.random(size=s.shape) - 0.5)))\n",
    "            noised.append(ns)\n",
    "        noised_steady_states.append(noised)\n",
    "    \n",
    "    ys = [torch.tensor(y.astype(np.float64), device=device) for y in steady_states]\n",
    "    Xs = [torch.tensor(np.array(X).astype(np.float64), device=device) for X in noised_steady_states]\n",
    "        \n",
    "    # Generate approximate bounds to be used for FBA and iterative projection versions\n",
    "    ls = []\n",
    "    us = []\n",
    "    for model_index, model, X, Y, mask in zip(list(range(len(models))), models, Xs, ys, masks):\n",
    "        l = torch.zeros((X.shape[0], X.shape[1]), dtype=torch.float, device=device)\n",
    "        u = torch.zeros((X.shape[0], X.shape[1]), dtype=torch.float, device=device)\n",
    "        for i, sample in enumerate(Y):\n",
    "            # Change bounds to the gap that was possible during the noise generation if unknown, and roughly the measured values for measured indices\n",
    "            sign = torch.sign(sample)\n",
    "            mask = torch.tensor(mask, dtype=torch.bool, device=device)\n",
    "            l[i, :] = (1 - base_noise_power * sign * ~mask) * sample - epsilon  \n",
    "            u[i, :] = (1 + base_noise_power * sign * ~mask) * sample + epsilon  \n",
    "    \n",
    "        ls.append(l)\n",
    "        us.append(u)\n",
    "        \n",
    "    containers = [[] for method in methods]\n",
    "\n",
    "    for model, A, basis, X, y, mask, l, u in zip(models, As, ss_bases, Xs, ys, masks, ls, us):\n",
    "        obj_coefs = {rxn.id: rxn.objective_coefficient for rxn in model.reactions if rxn.objective_coefficient != 0}\n",
    "        print(obj_coefs)\n",
    "        print([r.id for r in model.reactions if 'biomass' in r.id.lower()])\n",
    "        if len(obj_coefs) == 0:\n",
    "            growth_related_reactions = [r.id for r in model.reactions if 'biomass' in r.id.lower()]\n",
    "            assert len(growth_related_reactions) == 1\n",
    "            obj_coefs = {growth_related_reactions[0]: 1}\n",
    "        assert len(obj_coefs) == 1 and all([v == 1 for k, v in obj_coefs.items()])\n",
    "        objective_reaction_ids = obj_coefs.popitem()[0]\n",
    "\n",
    "        with model:\n",
    "            unknown_indices = [q for q in range(len(mask)) if ~(mask[q])]\n",
    "            measured_indices = [q for q in range(len(mask)) if mask[q]]\n",
    "\n",
    "            for method, container in zip(methods, containers): \n",
    "                # print(\"A shape, X shape:\", A.shape, X.shape)\n",
    "                proj = method(model=model, stoichiometric_matrix=A,\n",
    "                              unknown_indices=unknown_indices, measured_indices=measured_indices, steady_state_basis_matrix=basis, \n",
    "                              l_bounds=l, u_bounds=u, device=device, acond=acond, rcond=rcond,\n",
    "                              objective_id=objective_reaction_ids,\n",
    "                              dtype=torch.float)\n",
    "                y_pred = proj.forward(X.to(dtype=torch.float, device=device), l_bounds=l, u_bounds=u)\n",
    "                container.append(y_pred)\n",
    "                del proj\n",
    "    for i, y in enumerate(ys):\n",
    "        print(i)\n",
    "        for method_name, container in zip(method_names, containers):\n",
    "            for metric in ['spearmanr', 'l2']:\n",
    "                if metric == 'l2':\n",
    "                    continue\n",
    "                corr_func = stats.spearmanr if metric == 'spearmanr' else lambda a, b, nan_policy='omit': (-scipy.linalg.norm((a - b).values, axis=0), 0)\n",
    "                for masking in ['all', 'known', 'unknown']:\n",
    "                    if masking == 'all':\n",
    "                        continue\n",
    "                        mask = torch.ones_like(y[0], dtype=torch.bool, device=device)\n",
    "                    elif masking == 'known':\n",
    "                        mask = masks[i]\n",
    "                    else:\n",
    "                        mask = ~masks[i]\n",
    "                    for axis in ['per sample', 'per reaction']:\n",
    "                        # print(\"mask shape and sum:\", mask.shape, sum(mask))\n",
    "                        # data = y[:, mask]\n",
    "                        preds = container[i][:, mask].cpu().numpy()\n",
    "                        data = y[:, mask].cpu().numpy()\n",
    "                        if axis == 'per sample':\n",
    "                            # continue\n",
    "                            data = data.transpose()\n",
    "                            preds = preds.transpose()\n",
    "                            # assert sizes match and make them into dfs\n",
    "                        assert data.shape == preds.shape\n",
    "                        data = pd.DataFrame(data)\n",
    "                        preds = pd.DataFrame(preds)\n",
    "                        \n",
    "                        # print(data.shape, preds.shape, data.columns, preds.columns)\n",
    "                        \n",
    "                        corrs, _, full_corr, _ = util.run_correlation_tests(data, preds, corr_func=corr_func, parallel=False)\n",
    "                        # function is run per columns, transpose if doing per sample.\n",
    "                        # print(len(corrs), y[:, mask].shape, data.shape, preds.shape)\n",
    "                        if axis == 'per sample':\n",
    "                            assert len(corrs) == y[:, mask].shape[0]\n",
    "                        else:\n",
    "                            assert len(corrs) == y[:, mask].shape[1]\n",
    "                        for val in corrs.values():\n",
    "                            known_varying_entries.append({'known_frac': known_frac, 'model': model_name_to_organism[models[i].id], 'method': method_name, 'metric': metric, 'axis': axis, 'masking': masking, 'value': val})\n",
    "        \n",
    "    print(\"Finished iteration for known fraction {}\".format(known_frac))\n",
    "    \n",
    "known_varying_results = pd.DataFrame.from_records(known_varying_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6940106be24716c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = known_varying_results.loc[(known_varying_results['metric'] == 'spearmanr') &  (known_varying_results['axis'] == 'per reaction') & (known_varying_results['masking'] == 'unknown')]\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "\n",
    "filtered['method'] = filtered['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\")\n",
    "\n",
    "filtered['method'] = pd.Categorical(filtered['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                ])\n",
    "plt.xlabel(\"Fraction of known reactions\")\n",
    "plt.ylabel(\"Per Reaction Spearman Correlation\")\n",
    "\n",
    "# sns.lineplot(data=filtered, hue=\"method\", x='known_frac', y=\"value\", style='model')\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='known_frac', y=\"value\", marker=\"o\")\n",
    "filename =  \"exact_knownfrac_varying_rxn_unknown.png\"\n",
    "plt.gcf().savefig(os.path.join(export_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56048411e6146b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = known_varying_results.loc[(known_varying_results['metric'] == 'spearmanr') &  (known_varying_results['axis'] == 'per reaction') & (known_varying_results['masking'] == 'known')]\n",
    "# sns.lineplot(data=filtered, hue=\"method\", x='known_frac', y=\"value\", style='model')\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='known_frac', y=\"value\", marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d91079-6e52-43f6-b067-f189df036e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = known_varying_results.loc[(known_varying_results['metric'] == 'spearmanr') &  (known_varying_results['axis'] == 'per sample') & (known_varying_results['masking'] == 'unknown')]\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "\n",
    "filtered['method'] = filtered['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\")\n",
    "\n",
    "filtered['method'] = pd.Categorical(filtered['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                ])\n",
    "plt.xlabel(\"Fraction of known reactions\")\n",
    "plt.ylabel(\"Per Sample Spearman Correlation\")\n",
    "\n",
    "# sns.lineplot(data=filtered, hue=\"method\", x='known_frac', y=\"value\", style='model')\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='known_frac', y=\"value\", marker=\"o\")\n",
    "filename =  \"exact_knownfrac_varying_sample_unknown.png\"\n",
    "plt.gcf().savefig(os.path.join(export_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c7aad-ba99-4573-86c8-8679b317997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = known_varying_results.loc[(known_varying_results['metric'] == 'spearmanr') &  (known_varying_results['axis'] == 'per sample') & (known_varying_results['masking'] == 'known')]\n",
    "# sns.lineplot(data=filtered, hue=\"method\", x='known_frac', y=\"value\", style='model')\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='known_frac', y=\"value\", marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636643bf-80c5-468e-b097-27d90151ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_varying_results.to_csv(os.path.join(export_path, \"figure_recreation_data\", \"exact_noisy_data_known\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd806ce28b620f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Check dependences of performance on noise power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9606e-6496-4676-9079-aab8f577e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "          FbaProjection, \n",
    "          FbaProjectionLowMidConfidence,\n",
    "          FbaProjectionHighMidConfidence,\n",
    "          FBAWrapper,\n",
    "          IMATWrapper,\n",
    "          MoMAWrapper\n",
    "            ]\n",
    "method_names = [m.__repr__(None) for m in methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75915408fd2d01c1",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "noise_power_steps = list(np.linspace(start=0.01, stop=4, num=20, endpoint=True))\n",
    "\n",
    "noise_varying_entries = list()\n",
    "for i, cur_noise_power in enumerate(noise_power_steps):\n",
    "    print(\"noise level: {}\".format(noise_power_steps[i]))\n",
    "    ss_fluxes = list()\n",
    "    perturbed_fluxes = list()\n",
    "    names = list()\n",
    "    masks = list()\n",
    "\n",
    "    coefficients = [np.random.random(size=(basis.shape[1], n_samples_per_graph)) for basis in ss_bases]\n",
    "    steady_states = [(basis @ coef).transpose() for basis, coef in zip(ss_bases, coefficients)]     \n",
    "    known_indices_list = [sorted(np.random.choice(np.array(list(range(nss.shape[1]))), size=math.ceil(base_frac_known_reactions * nss.shape[1]), replace=False)) for nss in steady_states]\n",
    "    masks = list()\n",
    "    noised_steady_states = list()\n",
    "    for ss, idxs in zip(steady_states, known_indices_list):\n",
    "        mask = torch.zeros(ss.shape[1],dtype=bool, device=device)\n",
    "        mask[idxs] = True\n",
    "        # print(\"mask sum:\", sum(mask))\n",
    "        masks.append(mask)\n",
    "        noised = list()\n",
    "        # print(\"ss shape:\", ss.shape)\n",
    "        for s in ss:\n",
    "            # print(\"s shape:\", s.shape)\n",
    "            ns = s * np.where(mask.cpu(), 1, (1 + cur_noise_power * 2 * (np.random.random(size=s.shape) - 0.5)))\n",
    "            noised.append(ns)\n",
    "        noised_steady_states.append(noised)\n",
    "    \n",
    "    ys = [torch.tensor(y.astype(np.float64), device=device) for y in steady_states]\n",
    "    Xs = [torch.tensor(np.array(X).astype(np.float64), device=device) for X in noised_steady_states]\n",
    "        \n",
    "    # Generate approximate bounds to be used for FBA and iterative projection versions\n",
    "    ls = []\n",
    "    us = []\n",
    "    for model_index, model, X, Y, mask in zip(list(range(len(models))), models, Xs, ys, masks):\n",
    "        l = torch.zeros((X.shape[0], X.shape[1]), dtype=torch.float, device=device)\n",
    "        u = torch.zeros((X.shape[0], X.shape[1]), dtype=torch.float, device=device)\n",
    "        for i, sample in enumerate(Y):\n",
    "            # Change bounds to the gap that was possible during the noise generation if unknown, and roughly the measured values for measured indices\n",
    "            sign = torch.sign(sample)\n",
    "            l[i, :] = (1 - cur_noise_power * sign * ~mask) * sample - epsilon  \n",
    "            u[i, :] = (1 + cur_noise_power * sign * ~mask) * sample + epsilon  \n",
    "    \n",
    "        ls.append(l)\n",
    "        us.append(u)\n",
    "        \n",
    "    containers = [[] for method in methods]\n",
    "    for model, A, basis, X, y, mask, l, u in zip(models, As, ss_bases, Xs, ys, masks, ls, us):\n",
    "        obj_coefs = {rxn.id: rxn.objective_coefficient for rxn in model.reactions if rxn.objective_coefficient != 0}\n",
    "        print(obj_coefs)\n",
    "        print([r.id for r in model.reactions if 'biomass' in r.id.lower()])\n",
    "        if len(obj_coefs) == 0:\n",
    "            growth_related_reactions = [r.id for r in model.reactions if 'biomass' in r.id.lower()]\n",
    "            assert len(growth_related_reactions) == 1\n",
    "            obj_coefs = {growth_related_reactions[0]: 1}\n",
    "        assert len(obj_coefs) == 1 and all([v == 1 for k, v in obj_coefs.items()])\n",
    "        objective_reaction_ids = obj_coefs.popitem()[0]\n",
    "\n",
    "        with model:\n",
    "            unknown_indices = [q for q in range(len(mask)) if ~(mask[q])]\n",
    "            measured_indices = [q for q in range(len(mask)) if mask[q]]\n",
    "            for method, container in zip(methods, containers): \n",
    "                # print(\"A shape, X shape:\", A.shape, X.shape)\n",
    "                proj = method(model=model, stoichiometric_matrix=A,\n",
    "                              unknown_indices=unknown_indices, measured_indices=measured_indices, steady_state_basis_matrix=basis, \n",
    "                              l_bounds=l, u_bounds=u, device=device, objective_id=objective_reaction_ids,\n",
    "                              acond=1e-2, rcond=1e-2,\n",
    "                              dtype=torch.float)\n",
    "                y_pred = proj.forward(X.to(dtype=torch.float, device=device), l_bounds=l, u_bounds=u)\n",
    "                container.append(y_pred)\n",
    "                del proj\n",
    "    for i, y in enumerate(ys):\n",
    "        print(i)\n",
    "        for method_name, container in zip(method_names, containers):\n",
    "            for metric in ['spearmanr', 'l2']:\n",
    "                if metric == 'l2':\n",
    "                    continue\n",
    "                corr_func = stats.spearmanr if metric == 'spearmanr' else lambda a, b, nan_policy='omit': (-scipy.linalg.norm((a - b).values, axis=0), 0)\n",
    "                for masking in ['all', 'known', 'unknown']:\n",
    "                    if masking == 'all':\n",
    "                        # mask = torch.ones_like(y[0], dtype=torch.bool)\n",
    "                        continue\n",
    "                    elif masking == 'known':\n",
    "                        mask = masks[i]\n",
    "                    else:\n",
    "                        mask = ~masks[i]\n",
    "                    for axis in ['per sample', 'per reaction']:\n",
    "                        preds = container[i][:, mask].cpu().numpy()\n",
    "                        data = y[:, mask].cpu().numpy()\n",
    "                        if axis == 'per sample':\n",
    "                            # continue ## unused currently.\n",
    "                            data = data.transpose()\n",
    "                            preds = preds.transpose()\n",
    "                            # assert sizes match and make them into dfs\n",
    "                        assert data.shape == preds.shape\n",
    "                        data = pd.DataFrame(data)\n",
    "                        preds = pd.DataFrame(preds)\n",
    "                        \n",
    "                        # print(data.shape, preds.shape, data.columns, preds.columns)\n",
    "                        \n",
    "                        corrs, _, full_corr, _ = util.run_correlation_tests(data, preds, corr_func=corr_func, parallel=False)\n",
    "                        # function is run per columns, transpose if doing per sample.\n",
    "                        # print(len(corrs), y[:, mask].shape, data.shape, preds.shape)\n",
    "                        if axis == 'per sample':\n",
    "                            assert len(corrs) == y[:, mask].shape[0]\n",
    "                        else:\n",
    "                            assert len(corrs) == y[:, mask].shape[1]\n",
    "                        for val in corrs.values():\n",
    "                            noise_varying_entries.append({'noise_power': cur_noise_power, 'model': model_name_to_organism[models[i].id], 'method': method_name, 'metric': metric, 'axis': axis, 'masking': masking, 'value': val})\n",
    "        \n",
    "    print(\"Finished iteration for noise power {}\".format(cur_noise_power))\n",
    "    \n",
    "noise_varying_results = pd.DataFrame.from_records(noise_varying_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5269c-8306-4c73-a094-eeeab7de5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_varying_results.to_csv(os.path.join(export_path, \"figure_recreation_data\", \"exact_noisy_data_noise\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d3765819c4677",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = noise_varying_results.loc[(noise_varying_results['metric'] == 'spearmanr') &  (noise_varying_results['axis'] == 'per reaction') & (noise_varying_results['masking'] == 'unknown')]\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "\n",
    "filtered['method'] = filtered['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\")\n",
    "\n",
    "filtered['method'] = pd.Categorical(filtered['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                ])\n",
    "plt.xlabel(\"Noise Power δ\")\n",
    "plt.ylabel(\"Per Reaction Spearman Correlation\")\n",
    "\n",
    "# sns.lineplot(data=filtered, hue=\"method\", x='noise_level', y=\"value\", style='model')\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='noise_power', y=\"value\", marker=\"o\")\n",
    "filename =  \"exact_noise_varying_rxn_unknown.png\"\n",
    "plt.gcf().savefig(os.path.join(export_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0caf3253ea5982c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = noise_varying_results.loc[(noise_varying_results['metric'] == 'spearmanr') &  (noise_varying_results['axis'] == 'per reaction') & (noise_varying_results['masking'] == 'known')]\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='noise_power', y=\"value\", marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397085949feb9b2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = noise_varying_results.loc[(noise_varying_results['metric'] == 'spearmanr') &  (noise_varying_results['axis'] == 'per sample') & (noise_varying_results['masking'] == 'unknown')]\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "\n",
    "filtered['method'] = filtered['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\")\n",
    "\n",
    "filtered['method'] = pd.Categorical(filtered['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                ])\n",
    "plt.xlabel(\"Noise Power δ\")\n",
    "plt.ylabel(\"Per Sample Spearman Correlation\")\n",
    "\n",
    "# sns.lineplot(data=filtered, hue=\"method\", x='noise_level', y=\"value\", style='model')\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='noise_power', y=\"value\", marker=\"o\")\n",
    "filename =  \"exact_noise_varying_sample_unknown.png\"\n",
    "plt.gcf().savefig(os.path.join(export_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71fcbf-b57b-4a6e-809e-ca18e483b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = noise_varying_results.loc[(noise_varying_results['metric'] == 'spearmanr') &  (noise_varying_results['axis'] == 'per sample') & (noise_varying_results['masking'] == 'known')]\n",
    "sns.lineplot(data=filtered.sort_values(by=[\"method\", \"model\"]), hue=\"method\", x='noise_power', y=\"value\", marker=\"o\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
