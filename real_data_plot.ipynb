{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44445fd717516f31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"real_data_experiment_files/outputs\"\n",
    "export_path = \"real_data_experiment_files/figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9dcd9ad6bd38b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_data(model_name):\n",
    "    flux_data = {}\n",
    "    group_data = {}\n",
    "    leave_one_out_predictions = {}\n",
    "    full_predictions = {}\n",
    "    pathway_to_reactions = {}\n",
    "    \n",
    "    files = os.listdir(data_path)\n",
    "    # search for a directory with the model's name\n",
    "    if model_name not in files:\n",
    "        raise ValueError(f\"Model {model_name} not found in data path {data_path}\")\n",
    "    model_dir = os.path.join(data_path, model_name)\n",
    "    model_files = os.listdir(model_dir)\n",
    "    print(model_files)\n",
    "    # assert \"pathways_to_rxns.csv\" in model_files\n",
    "    # pathway information is directly in model_files, grap that\n",
    "    # a csv with pathway id and then variable length sequence of reaction ids, read as a dict mapping pathway id to list of reaction ids\n",
    "    # pathways_to_rxns = {}\n",
    "    # df = pd.read_csv(os.path.join(os.path.join(data_path, model_name, \"pathways_to_rxns.csv\")), header=None)\n",
    "    # for index, row in df.iterrows():\n",
    "    #     pathway_id = row[0]\n",
    "    #     # separator is ;\n",
    "    #     reaction_ids = row[1:].dropna()\n",
    "    #     # separate by ;\n",
    "    #     reaction_ids = reaction_ids.astype(str).str.split(\";\").explode().tolist()\n",
    "    #     pathways_to_rxns[pathway_id] = reaction_ids\n",
    "    # assert \"groups\" in model_files\n",
    "    # now read group information from the \"group\" subdirectory. Each file name there corresponds to a key, and the read dataframe to the values\n",
    "    # group_files = os.listdir(os.path.join(data_path, model_name, \"groups\"))\n",
    "    # for f in group_files:\n",
    "    #     if f.endswith(\".csv\"):\n",
    "    #         key = f[:-4]\n",
    "    #         group_data[key] = pd.read_csv(os.path.join(data_path, model_name, \"groups\", f), index_col=0)\n",
    "    # assert \"fluxes\" in model_files and \"predictions\" in model_files\n",
    "    # assert \"leave_one_out\" in os.listdir(os.path.join(data_path, model_name, \"predictions\"))\n",
    "    # assert \"full\" in os.listdir(os.path.join(data_path, model_name, \"predictions\"))\n",
    "    # next are the flux data and flux predictions. Structure is as follows: \"fluxes\" subdirectory has csv files, the names are keys\n",
    "    # and the dataframes are the values.\n",
    "    # Predictions have leave_one_out and full subdirectories, with each key of \"fluxes\" matching a subdirectory within those two.\n",
    "    # make sure they match, and fill both leave_one_out_predictions and full_predictions, and flux_data accordingly (so predictions dicts\n",
    "    # have one more level, of the method names (the csvs)).\n",
    "    # If there isn't a match, make sure it's something missing from the predictions only, and rint that warning.\n",
    "    \n",
    "    flux_files = os.listdir(os.path.join(data_path, model_name, \"fluxes\"))\n",
    "    for f in flux_files:\n",
    "        print(f)\n",
    "        if f.endswith(\".csv\"):\n",
    "            key = f[:-4]\n",
    "            flux_data[key] = pd.read_csv(os.path.join(data_path, model_name, \"fluxes\", f), index_col=0)\n",
    "            # check for predictions\n",
    "            loo_dir = os.path.join(data_path, model_name, \"predictions\", \"leave_one_out\", key)\n",
    "            full_dir = os.path.join(data_path, model_name, \"predictions\", \"full\", key)\n",
    "            if os.path.isdir(loo_dir):\n",
    "                method_files = os.listdir(loo_dir)\n",
    "                leave_one_out_predictions[key] = {}\n",
    "                for method_file in method_files:\n",
    "                    if method_file.endswith(\".csv\"):\n",
    "                        method_name = method_file[:-4]\n",
    "                        leave_one_out_predictions[key][method_name] = pd.read_csv(os.path.join(loo_dir, method_file), index_col=0)\n",
    "            else:\n",
    "                print(f\"Warning: No leave_one_out predictions found for key {key} in model {model_name}\")\n",
    "            if os.path.isdir(full_dir):\n",
    "                method_files = os.listdir(full_dir)\n",
    "                full_predictions[key] = {}\n",
    "                for method_file in method_files:\n",
    "                    if method_file.endswith(\".csv\"):\n",
    "                        method_name = method_file[:-4]\n",
    "                        full_predictions[key][method_name] = pd.read_csv(os.path.join(full_dir, method_file), index_col=0)\n",
    "            else:\n",
    "                print(f\"Warning: No full predictions found for key {key} in model {model_name}\")\n",
    "    return flux_data, leave_one_out_predictions, full_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc869eab896fa4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_loo_correlations(flux_data, predictions, abs_values):\n",
    "    # Go over each data source in flux_data. Compute per-column (reaction) and per row (sample) Spearman correlations between each method's predictions on the matching data and the true fluxes. Store the results in a dataframe with columns: method, data, axis, correlation.\n",
    "    entries = []\n",
    "    for data_source in flux_data:\n",
    "        print(\"data source:\", data_source)\n",
    "        if data_source.replace(\"_\", \" \") not in relevant_loos:\n",
    "            print(\"Skipping data source\")\n",
    "            continue\n",
    "        true_fluxes = flux_data[data_source]\n",
    "        # check if predictions exist\n",
    "        if data_source not in predictions:\n",
    "            print(f\"Warning: No predictions for data source {data_source}\")\n",
    "            continue\n",
    "        predictions_for_data = predictions[data_source]\n",
    "        for method in predictions_for_data:\n",
    "            # ignore raw input here\n",
    "            if method == \"RawInput\" or method == \"Reference Values\":\n",
    "                continue\n",
    "            predicted_fluxes = predictions_for_data[method].fillna(0)\n",
    "            if predicted_fluxes.shape[1] == 0:\n",
    "                print(\"Empty predictions for method {}, data source {}\".format(method, data_source))\n",
    "                continue\n",
    "            # align indices and columns\n",
    "            common_indices = true_fluxes.index.intersection(predicted_fluxes.index)\n",
    "            common_columns = true_fluxes.columns.intersection(predicted_fluxes.columns)\n",
    "            # print(f\"Computing correlations for data source: {data_source}, method: {method}\")\n",
    "            # print(f\"Common indices: {len(common_indices)}, Common columns: {len(common_columns)}\")\n",
    "            # print(f\"True fluxes shape: {true_fluxes.shape}, Predicted fluxes shape: {predicted_fluxes.shape}\")\n",
    "            # print index column samples\n",
    "            # print(f\"True fluxes indices: {true_fluxes.index.tolist()[:5]}, Predicted fluxes indices: {predicted_fluxes.index.tolist()[:5]}\")\n",
    "            # print(f\"True fluxes columns: {true_fluxes.columns.tolist()[:5]}, Predicted fluxes columns: {predicted_fluxes.columns.tolist()[:5]}\")\n",
    "            assert len(common_indices) > 0, f\"No common indices between true fluxes and predictions for data source {data_source} using method {method}\"\n",
    "            assert len(common_columns) > 0, f\"No common columns between true fluxes and predictions for data source {data_source} using method {method}\"\n",
    "            true_aligned = true_fluxes.loc[common_indices, common_columns]\n",
    "            predicted_aligned = predicted_fluxes.loc[common_indices, common_columns]\n",
    "            if abs_values:\n",
    "                true_aligned = abs(true_aligned)\n",
    "                predicted_aligned = abs(predicted_aligned)\n",
    "            # compute per-column correlations\n",
    "            col_correlations = dict()\n",
    "            p_values = dict()\n",
    "            for reaction in predicted_aligned.columns:\n",
    "                if (~predicted_aligned[reaction].isna()).sum() <= 3:\n",
    "                    continue\n",
    "                corr_value, p_value = stats.spearmanr(predicted_aligned[reaction], true_aligned[reaction], nan_policy='omit')\n",
    "                col_correlations[reaction] = corr_value\n",
    "                p_values[reaction] = p_value\n",
    "            for reaction, corr_value in col_correlations.items():\n",
    "                entries.append({\n",
    "                    \"method\": method,\n",
    "                    \"data\": data_source.replace(\"_\", \" \"),\n",
    "                    \"axis\": \"reaction\",\n",
    "                    \"correlation\": corr_value,\n",
    "                    \"p-val\": p_values[reaction]\n",
    "                    \n",
    "                })\n",
    "            # compute per-row correlations\n",
    "            row_correlations = dict()\n",
    "            p_values = dict()\n",
    "            for sample in predicted_aligned.index:\n",
    "                if (~predicted_aligned.loc[sample].isna()).sum() <= 3:\n",
    "                    continue\n",
    "                corr_value, p_value = stats.spearmanr(predicted_aligned.loc[sample], true_aligned.loc[sample], nan_policy='omit')\n",
    "                row_correlations[sample] = corr_value\n",
    "                p_values[sample] = p_value\n",
    "            print(\"data source {}, method {}, samples mean p-value {:.2e}, min p-value {:.2e}, max p-value {:.2e}\".format(data_source, method, \n",
    "                                                                                                                  np.mean(list(p_values.values())), np.min(list(p_values.values())), np.max(list(p_values.values()))))\n",
    "            for sample, corr_value in row_correlations.items():\n",
    "                entries.append({\n",
    "                    \"method\": method,\n",
    "                    \"data\": data_source.replace(\"_\", \" \"),\n",
    "                    \"axis\": \"sample\",\n",
    "                    \"correlation\": corr_value,\n",
    "                    \"p-val\": p_values[sample]\n",
    "                })\n",
    "    return pd.DataFrame(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90230474b22206a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for full correlations, instead of matching data and predictions, we'll compute correlations across all pairs of data-prediction sources, with columns for the entries corresponding to both the input data and the target data\n",
    "def compute_full_correlations(flux_data, predictions, abs_values):\n",
    "    # Go over each data source in flux_data. Compute per-column (reaction) and per row (sample) Spearman correlations between each method's predictions on the matching data and the true fluxes. Store the results in a dataframe with columns: method, data, axis, correlation.\n",
    "    \n",
    "    entries = []\n",
    "    predictions = {k.replace(\"_\", \" \"): v for (k, v) in predictions.items()}\n",
    "    flux_data = {k.replace(\"_\", \" \"): v for (k, v) in flux_data.items()}\n",
    "    targets = sorted(set(flux_data.keys()).intersection(relevant_targets))\n",
    "    inputs = sorted(set(predictions.keys()).intersection(relevant_inputs))\n",
    "    for target_source in targets:\n",
    "        print(\"target source:\", target_source)\n",
    "        for input_source in inputs:\n",
    "            print(\"input source:\", input_source)\n",
    "            true_fluxes = flux_data[target_source]\n",
    "            predicted_fluxes = predictions[input_source]\n",
    "            for method in predicted_fluxes:\n",
    "                print(\"method:\", method)\n",
    "                predicted_fluxes_method = predicted_fluxes[method].fillna(0)\n",
    "                # align indices and columns\n",
    "                common_indices = true_fluxes.index.intersection(predicted_fluxes_method.index)\n",
    "                common_columns = true_fluxes.columns.intersection(predicted_fluxes_method.columns)\n",
    "                print(f\"Computing correlations for input source: {input_source}, target_source: {target_source}, method: {method}\")\n",
    "                # print(f\"Common indices: {len(common_indices)}, Common columns: {len(common_columns)}\")\n",
    "                # print(f\"True fluxes shape: {true_fluxes.shape}, Predicted fluxes shape: {predicted_fluxes_method.shape}\")\n",
    "                # print(f\"True fluxes indices: {true_fluxes.index.tolist()[:5]}, Predicted fluxes indices: {predicted_fluxes_method.index.tolist()[:5]}\")\n",
    "                # print(f\"True fluxes columns: {true_fluxes.columns.tolist()[:5]}, Predicted fluxes columns: {predicted_fluxes_method.columns.tolist()[:5]}\")\n",
    "                if not len(common_indices) or not len(common_columns):\n",
    "                    print(f\"Skipping input source: {input_source}, target_source: {target_source}, method: {method} due to no common indices or columns\")\n",
    "                    continue\n",
    "                # assert len(common_indices) > 0, f\"No common indices between true fluxes for target {target_source} and predictions for input {input_source} using method {method}\"\n",
    "                # assert len(common_columns) > 0, f\"No common columns between true fluxes for target {target_source} and predictions for input {input_source} using method {method}\"\n",
    "                true_aligned = true_fluxes.loc[common_indices, common_columns]\n",
    "                predicted_aligned = predicted_fluxes_method.loc[common_indices, common_columns]\n",
    "                if abs_values:\n",
    "                    true_aligned = abs(true_aligned)\n",
    "                    predicted_aligned = abs(predicted_aligned)\n",
    "                # compute per-column correlations\n",
    "                col_correlations = dict()\n",
    "                p_values = dict()\n",
    "                for reaction in predicted_aligned.columns:\n",
    "                    if len(predicted_aligned[reaction]) <= 3:\n",
    "                        continue\n",
    "                    corr_value, p_value = stats.spearmanr(predicted_aligned[reaction], true_aligned[reaction], nan_policy='omit')\n",
    "                    p_values[reaction] = p_value\n",
    "                    col_correlations[reaction] = corr_value\n",
    "                    p_values[reaction] = p_value\n",
    "                    # \n",
    "                    # if target_source == \"activities\" and input_source == \"activities\" and method == \"RawInput\":\n",
    "                    #     print(f\"Reaction: {reaction}, Correlation: {corr_value}\")\n",
    "\n",
    "                # col_correlations = predicted_aligned.corrwith(true_aligned, axis=0, method='spearman')\n",
    "                # print(f\"Computing correlations for input: {input_source}, target: {target_source}, method: {method}\")\n",
    "                # print(f\"Cleaned names: input: {input_source.replace('_', ' ')}, target: {target_source.replace('_', ' ')}\")\n",
    "                for reaction, corr_value in col_correlations.items():\n",
    "                    entries.append({\n",
    "                        \"method\": method,\n",
    "                        \"input data\": input_source.replace(\"_\", \" \"),\n",
    "                        \"target data\": target_source.replace(\"_\", \" \"),\n",
    "                        \"axis\": \"reaction\",\n",
    "                        \"correlation\": corr_value,\n",
    "                        \"p-val\": p_values[reaction]\n",
    "                    })\n",
    "                # compute per-row correlations\n",
    "                row_correlations = dict()\n",
    "                p_values = dict()\n",
    "                for sample in predicted_aligned.index:\n",
    "                    corr_value, p_value = stats.spearmanr(predicted_aligned.loc[sample], true_aligned.loc[sample], nan_policy='omit')\n",
    "                    row_correlations[sample] = corr_value\n",
    "                    p_values[sample] = p_value\n",
    "                # row_correlations = predicted_aligned.corrwith(true_aligned, axis=1, method='spearman')\n",
    "                print(\"target source {}, input source {}, method {}, samples mean p-value {:.2e}, min p-value {:.2e}, max p-value {:.2e}\".format(target_source, input_source, method, \n",
    "                                                                                                                      np.mean(list(p_values.values())), np.min(list(p_values.values())), np.max(list(p_values.values()))))\n",
    "                for sample, corr_value in row_correlations.items():\n",
    "                    entries.append({\n",
    "                        \"method\": method,\n",
    "                        \"input data\": input_source.replace(\"_\", \" \"),\n",
    "                        \"target data\": target_source.replace(\"_\", \" \"),\n",
    "                        \"axis\": \"sample\",\n",
    "                        \"p-val\": p_values[sample],\n",
    "                        \"correlation\": corr_value\n",
    "                    })\n",
    "    return pd.DataFrame(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2013ff3db3227",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_full_corrs(df, model_name):\n",
    "    # Create two multi-plots, each one a matrix of subplots. One for sample-based correlations and one for reaction-based correlations. \n",
    "    # Each subplot will have a boxenplot with hue as method and y as correlation, and data using the corresponding input-target pair.\n",
    "    \n",
    "    # start with reaction plots\n",
    "    rxns_full_correlation_df = df[df['axis'] == 'reaction']\n",
    "    targets = sorted(set(rxns_full_correlation_df['target data'].unique()).intersection(relevant_targets))\n",
    "    inputs = sorted(set(rxns_full_correlation_df['input data'].unique()).intersection(relevant_inputs))\n",
    "    print(\"Targets: \", targets)\n",
    "    print(\"Inputs: \", inputs)\n",
    "    # subplots = plt.figure(figsize=(5 * len(inputs), 3 * len(targets)))\n",
    "    # axes = {}\n",
    "    for i, target_data in enumerate(sorted(targets)):\n",
    "        for j, input_data in enumerate(sorted(inputs)):\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            # axes[(input_data, target_data)] = plt.subplot2grid((len(targets), len(inputs)), (i, j), fig=subplots)\n",
    "            # plt.title(f\"Input: {input_data}\\nTarget: {target_data}\")\n",
    "            plt.xlabel(\"Method\")\n",
    "            data = rxns_full_correlation_df[(rxns_full_correlation_df['input data'] == input_data) & (rxns_full_correlation_df['target data'] == target_data)]\n",
    "            # boxenplot colored by method\n",
    "            if len(data) > 10:\n",
    "                sns.boxenplot(data=data.sort_values(by=['method']), hue='method', y='correlation')#, ax=axes[(input_data, target_data)])\n",
    "            else:\n",
    "                sns.barplot(data=data.sort_values(by=['method']), hue='method', y='correlation')#, ax=axes[(input_data, target_data)])                \n",
    "            # no legend\n",
    "            # try:\n",
    "            #     axes[(input_data, target_data)].get_legend().remove()\n",
    "            # except Exception as e:\n",
    "            #     pass\n",
    "            # bbox = axes[(input_data, target_data)].get_tightbbox(subplots.canvas.get_renderer())\n",
    "            filename =  \"{}_rxns_full_{}_to_{}\".format(model_name, input_data, target_data) + \".png\"\n",
    "            print(filename)\n",
    "            # plt.gcf().savefig(os.path.join(export_path, filename))\n",
    "            plt.show()\n",
    "\n",
    "            # plt.xticks(rotation=45)\n",
    "    # make sure there's only one global legend, outside to the right of the plot area\n",
    "    # handles, labels = subplots.gca().get_legend_handles_labels()\n",
    "    # subplots.legend(handles, labels, title=\"Method\", bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "    # plt.suptitle(\"{} reaction-based full correlations\".format(model_name), fontsize=16)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "            \n",
    "    # now sample plots\n",
    "    samples_full_correlation_df = df[df['axis'] == 'sample']\n",
    "    targets = sorted(set(samples_full_correlation_df['target data'].unique()).intersection(relevant_targets))\n",
    "    inputs = sorted(set(samples_full_correlation_df['input data'].unique()).intersection(relevant_inputs))\n",
    "    # subplots = plt.figure(figsize=(5 * len(inputs), 3 * len(targets)))\n",
    "    # axes = {}\n",
    "    for i, target_data in enumerate(sorted(targets)):\n",
    "        for j, input_data in enumerate(sorted(inputs)):\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            # axes[(input_data, target_data)] = plt.subplot2grid((len(samples_full_correlation_df['target data'].unique()), len(samples_full_correlation_df['input data'].unique())), (i, j), fig=subplots)\n",
    "            # plt.title(f\"Input: {input_data}\\nTarget: {target_data}\")\n",
    "            plt.xlabel(\"Method\")\n",
    "            data = samples_full_correlation_df[(samples_full_correlation_df['input data'] == input_data) & (samples_full_correlation_df['target data'] == target_data)]\n",
    "            print(data)\n",
    "            # boxenplot colored by method\n",
    "            if len(data) > 10:\n",
    "                sns.boxenplot(data=data.sort_values(by=['method']), hue='method', y='correlation')#, ax=axes[(input_data, target_data)])\n",
    "            else:\n",
    "                sns.barplot(data=data.sort_values(by=['method']), hue='method', y='correlation')#, ax=axes[(input_data, target_data)])                \n",
    "\n",
    "            # bbox = axes[(input_data, target_data)].get_tightbbox(subplots.canvas.get_renderer())\n",
    "            filename =  \"{}_samples_full_{}_to_{}\".format(model_name, input_data, target_data) + \".png\"\n",
    "            print(filename)\n",
    "            # plt.gcf().savefig(os.path.join(export_path, filename))\n",
    "            plt.show()\n",
    "            # no legend\n",
    "            # try:\n",
    "            #     axes[(input_data, target_data)].get_legend().remove()\n",
    "            # except Exception as e:\n",
    "            #     pass\n",
    "            # plt.xticks(rotation=45)\n",
    "    # make sure there's only one global legend, outside to the right of the plot area\n",
    "    # handles, labels = subplots.gca().get_legend_handles_labels()\n",
    "    # subplots.legend(handles, labels, title=\"Method\", bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "    # plt.suptitle(\"{} sample-based full correlations\".format(model_name), fontsize=16)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b2a78a8d40345",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_pathways(pathways_to_rxns, name_filter, min_length):\n",
    "    # filter pathways based on name_filter function and min_length\n",
    "    filtered_pathways = {}\n",
    "    for pathway, reactions in pathways_to_rxns.items():\n",
    "        if name_filter(pathway) and len(reactions) >= min_length:\n",
    "            filtered_pathways[pathway] = reactions\n",
    "    return filtered_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4778fa69a7dcfaa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_loos = ['activities', 'intracellular', 'fluxmapped activities', 'intracellular ACH-000019', 'intracellular ACH-000681', 'fold intracellular', 'NCI60 exchanges', \n",
    "                 'joint intracellular and exchanges ACH-000019', 'joint intracellular and exchanges ACH-000681']\n",
    "relevant_inputs = ['activities', 'fluxmapped activities', 'NCI60 exchanges']\n",
    "relevant_targets = ['NCI60 exchanges', 'intracellular ACH-000019', 'intracellular ACH-000681', 'intracellular', 'fold intracellular', 'joint intracellular and exchanges ACH-000019', 'joint intracellular and exchanges ACH-000681']\n",
    "relevant_methods = ['FBA', 'FBApro', 'FBAproLowMid', 'FBAproHighMid', 'iMAT', 'GIMME', 'Reference Values']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3afa7-681c-451c-9ac9-4ebea02e2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon1_flux_data, recon1_loo_predictions, recon1_full_predictions = get_model_data(\"recon1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880cfdf7-0e82-499c-95b5-08ced16452a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4f3935-de35-41a7-9880-f9ce1f85d250",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Recon1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c173a27-fa34-4c63-be63-f4d7057d220c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Leave-one-out predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20767d-2ade-4922-9d5f-f1c0ad6b5d59",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loo_correlation_df = compute_loo_correlations(recon1_flux_data, recon1_loo_predictions, abs_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a48424-792f-4dba-838d-8dcfb60d81a3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a multi-plot with two subplots, One for sample-based correlations and one for reaction-based correlations. Each one\n",
    "# will have a boxenplot with x as data y as correlation and hue as method.\n",
    "sns.set_style('whitegrid')\n",
    "g = sns.catplot(\n",
    "    data=loo_correlation_df.sort_values(by=['data', 'method']),\n",
    "    x=\"data\",\n",
    "    y=\"correlation\",\n",
    "    hue=\"method\",\n",
    "    col=\"axis\",\n",
    "    kind=\"boxen\",\n",
    "    height=5,\n",
    "    aspect=1.5,\n",
    "    sharey=False\n",
    ")\n",
    "g.set_axis_labels(\"Data Source\", \"Spearman Correlation\")\n",
    "g.set_titles(col_template=\"Recon1 {col_name} signed correlations\")\n",
    "# textwrap x tick labels, no rotation (remember it's a multiplot, do once per subplot)\n",
    "for ax in g.axes.flat:\n",
    "    labels = [textwrap.fill(label.get_text(), 15) for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(labels)\n",
    "g._legend.set_title(\"Method\")\n",
    "g._legend.set_bbox_to_anchor((1.1, 0.75))\n",
    "plt.tight_layout()\n",
    "\n",
    "filename =  \"recon1_loo_signed.png\"\n",
    "g.savefig(os.path.join(export_path, filename))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5a06a-d70f-4cc6-a3b3-567270d7b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-plot with two subplots, One for sample-based correlations and one for reaction-based correlations. Each one\n",
    "# will have a boxenplot with x as data y as correlation and hue as method.\n",
    "sns.set_style('whitegrid')\n",
    "g = sns.catplot(\n",
    "    data=loo_correlation_df.sort_values(by=['data', 'method']),\n",
    "    x=\"data\",\n",
    "    y=\"correlation\",\n",
    "    hue=\"method\",\n",
    "    col=\"axis\",\n",
    "    kind=\"bar\",\n",
    "    height=5,\n",
    "    aspect=1.5,\n",
    "    sharey=False\n",
    ")\n",
    "g.set_axis_labels(\"Data Source\", \"Spearman Correlation\")\n",
    "g.set_titles(col_template=\"Recon1 {col_name} signed correlations\")\n",
    "# textwrap x tick labels, no rotation (remember it's a multiplot, do once per subplot)\n",
    "for ax in g.axes.flat:\n",
    "    labels = [textwrap.fill(label.get_text(), 15) for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(labels)\n",
    "g._legend.set_title(\"Method\")\n",
    "g._legend.set_bbox_to_anchor((1.1, 0.75))\n",
    "plt.tight_layout()\n",
    "\n",
    "filename =  \"recon1_loo_signed.png\"\n",
    "g.savefig(os.path.join(export_path, filename))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9e8486-3fc6-4cc9-9a55-4b6ae9a61ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-plot with two subplots, One for sample-based correlations and one for reaction-based correlations. Each one\n",
    "# will have a boxenplot with x as data y as correlation and hue as method.\n",
    "sns.set(style=\"darkgrid\", font_scale=2)\n",
    "filter = (loo_correlation_df['axis'] == 'sample') & (\n",
    "    (loo_correlation_df['data'].str.contains('joint')) | (loo_correlation_df['data'].str.contains('NCI60')))\n",
    "replaced = loo_correlation_df.copy()\n",
    "replaced['data'] = replaced['data'].str.replace(\"joint intracellular and exchanges\", \"Joined fluxes\")\n",
    "replaced['data'] = replaced['data'].str.replace(\"ACH-000681\", \"A549\").str.replace(\"ACH-000019\", \"MCF7\")\n",
    "replaced['method'] = replaced['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\")\n",
    "\n",
    "replaced = replaced.loc[~replaced['method'].str.contains('Scale')]\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=replaced.loc[filter].sort_values(by=['data', 'method']),\n",
    "    x=\"data\",\n",
    "    y=\"correlation\",\n",
    "    hue=\"method\",\n",
    "    kind=\"bar\",\n",
    "    height=7,\n",
    "    aspect=1.5,\n",
    "    sharey=True\n",
    ")\n",
    "# g.set_axis_labels(\"Data Source\", \"Per-Sample Spearman Correlation\")\n",
    "plt.ylabel(\"Per-Sample Spearman Correlation\")\n",
    "plt.xlabel(\"\")\n",
    "g.set_titles(col_template=\"Core recon {col_name} signed correlations\")\n",
    "# textwrap x tick labels, no rotation (remember it's a multiplot, do once per subplot)\n",
    "for ax in g.axes.flat:\n",
    "    labels = [textwrap.fill(label.get_text(), 15) for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(labels)\n",
    "g._legend.set_title(\"Method\")\n",
    "g._legend.set_bbox_to_anchor((1.2, 0.7))\n",
    "plt.tight_layout()\n",
    "\n",
    "filename =  \"recon1_loo.png\"\n",
    "g.savefig(os.path.join(export_path, filename))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5dc7f-5389-4858-982d-432752a9980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-plot with two subplots, One for sample-based correlations and one for reaction-based correlations. Each one\n",
    "# will have a boxenplot with x as data y as correlation and hue as method.\n",
    "sns.set(style=\"darkgrid\", font_scale=2)\n",
    "filter = (loo_correlation_df['axis'] == 'sample') & (\n",
    "    (loo_correlation_df['data'].str.contains('joint')) | (loo_correlation_df['data'].str.contains('NCI60')))\n",
    "replaced = loo_correlation_df.copy()\n",
    "replaced['data'] = replaced['data'].str.replace(\"joint intracellular and exchanges\", \"Exchange & Intracellular\")\n",
    "replaced['data'] = replaced['data'].str.replace(\"ACH-000681\", \"A549\").str.replace(\"ACH-000019\", \"MCF7\")\n",
    "replaced['method'] = replaced['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\").str.replace(\"Reference Values\", \"Mid-bound Benchmark\")\n",
    "\n",
    "replaced = replaced.loc[~replaced['method'].str.contains('Scale') & ~replaced['method'].str.contains('Clip')]\n",
    "\n",
    "replaced['method'] = pd.Categorical(replaced['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                ])\n",
    "\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=replaced.loc[filter].sort_values(by=['data', 'method']),\n",
    "    x=\"data\",\n",
    "    y=\"correlation\",\n",
    "    hue=\"method\",\n",
    "    kind=\"bar\",\n",
    "    height=8,\n",
    "    aspect=1.5,\n",
    "    sharey=True\n",
    ")\n",
    "# g.set_axis_labels(\"Data Source\", \"Per-Sample Spearman Correlation\")\n",
    "plt.ylabel(\"Per-Sample Spearman Correlation\")\n",
    "plt.xlabel(\"\")\n",
    "g.set_titles(col_template=\"Core recon {col_name} signed correlations\")\n",
    "# textwrap x tick labels, no rotation (remember it's a multiplot, do once per subplot)\n",
    "for ax in g.axes.flat:\n",
    "    labels = [textwrap.fill(label.get_text(), 25) for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(labels)\n",
    "g._legend.set_title(\"Method\")\n",
    "g._legend.set_bbox_to_anchor((1.12, 0.7))\n",
    "plt.tight_layout()\n",
    "\n",
    "filename =  \"recon1_loo.png\"\n",
    "g.savefig(os.path.join(export_path, filename))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e218022-bd88-4814-9813-e9676660821e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Full predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf70e7-1c84-45fa-b4cf-e5a75937ffdf",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_correlation_df = compute_full_correlations(recon1_flux_data, recon1_full_predictions, abs_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4282fcb-dca0-429b-a601-f525ebb9593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_target_pairs = [('(Mapped Activities\\n->\\nNCI60 exchanges)'), \n",
    "                      # ('(Mapped Activities\\n->\\nFluxes MCF7)'),\n",
    "                      # ('(Mapped Activities\\n->\\nFluxes A549)'),\n",
    "                      ('(Mapped Activities\\n->\\nJoined Fluxes MCF7)'),\n",
    "                      ('(Mapped Activities\\n->\\nJoined Fluxes A549)'),                      \n",
    "                      ('(Activities\\n->\\nJoined Fluxes MCF7)'),\n",
    "                      ('(Activities\\n->\\nJoined Fluxes A549)'),                      \n",
    "                      # ('(NCI60 exchanges\\n->\\nFluxes A549)'),\n",
    "                      # ('(NCI60 exchanges\\n->\\nFluxes MCF7)'),\n",
    "                     ]\n",
    "# full_correlation_df['input data'].unique(), full_correlation_df['target data'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472c1dc-8db8-42e8-9d90-97a5a1e47883",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_correlation_df.copy()\n",
    "data['target data'] = data['target data'].str.replace(\"intracellular ACH-000019\", \"Fluxes MCF7\").str.replace(\n",
    "    \"intracellular ACH-000681\", \"Fluxes A549\").str.replace(\n",
    "    \"joint intracellular and exchanges ACH-000019\", \"Joined Fluxes MCF7\").str.replace(\n",
    "    \"joint intracellular and exchanges ACH-000681\", \"Joined Fluxes A549\")\n",
    "data['input data'] = data['input data'].str.replace(\"fluxmapped activities\", \"Mapped Activities\").str.replace(\"activities\", \"Activities\")\n",
    "input_target_values = data['input data'] + '\\n->\\n' + data['target data']\n",
    "data['input target pair'] = input_target_values\n",
    "print(data['input target pair'].unique())\n",
    "filter = input_target_values.str.contains('|'.join(input_target_pairs))\n",
    "data = data.loc[filter].loc[data['method'] != 'GIMME'] \n",
    "\n",
    "data = data.loc[~data['method'].str.contains('Scale')]\n",
    "\n",
    "# Create a multi-plot with two subplots, One for sample-based correlations and one for reaction-based correlations. Each one\n",
    "# will have a boxenplot with x as data y as correlation and hue as method.\n",
    "# sns.set_style('whitegrid')\n",
    "g = sns.catplot(\n",
    "    data=data.loc[data['axis'] == 'sample'].sort_values(by=['method', 'input target pair']),\n",
    "    x=\"input target pair\",\n",
    "    y=\"correlation\",\n",
    "    hue=\"method\",\n",
    "    # col=\"axis\",\n",
    "    kind=\"bar\",\n",
    "    height=7,\n",
    "    aspect=1.5,\n",
    "    sharey=False\n",
    ")\n",
    "g.set_axis_labels(\"Input Source -> Target Source\", \"Per-Sample Spearman Correlation\")\n",
    "# g.set_titles(col_template=\"Recon1 signed correlations\")\n",
    "# textwrap x tick labels, no rotation (remember it's a multiplot, do once per subplot)\n",
    "# for ax in g.axes.flat:\n",
    "#     labels = [textwrap.fill(label.get_text(), 15) for label in ax.get_xticklabels()]\n",
    "#     ax.set_xticklabels(labels)\n",
    "g._legend.set_title(\"Method\")\n",
    "g._legend.set_bbox_to_anchor((1.2, 0.7))\n",
    "plt.tight_layout()\n",
    "\n",
    "filename =  \"recon1_mapping.png\"\n",
    "g.savefig(os.path.join(export_path, filename))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd302689-d9ff-443d-90fb-effcc20bfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_target_pairs = [('(Mapped Activities\\n->\\nNCI60 exchanges)'), \n",
    "                      # ('(Mapped Activities\\n->\\nFluxes MCF7)'),\n",
    "                      # ('(Mapped Activities\\n->\\nFluxes A549)'),\n",
    "                      ('(Mapped Activities\\n->\\nExchange & Intracellular MCF7)'),\n",
    "                      ('(Mapped Activities\\n->\\nExchange & Intracellular A549)'),                      \n",
    "                      # ('(Activities\\n->\\nJoined Fluxes MCF7)'),\n",
    "                      # ('(Activities\\n->\\nJoined Fluxes A549)'),                      \n",
    "                      # ('(NCI60 exchanges\\n->\\nFluxes A549)'),\n",
    "                      # ('(NCI60 exchanges\\n->\\nFluxes MCF7)'),\n",
    "                     ]\n",
    "# full_correlation_df['input data'].unique(), full_correlation_df['target data'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d06336-a994-4cba-a6aa-ad946e4e9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_correlation_df.copy()\n",
    "data['target data'] = data['target data'].str.replace(\"intracellular ACH-000019\", \"Fluxes MCF7\").str.replace(\n",
    "    \"intracellular ACH-000681\", \"Fluxes A549\").str.replace(\n",
    "    \"joint intracellular and exchanges ACH-000019\",  \"Exchange & Intracellular MCF7\").str.replace(\n",
    "    \"joint intracellular and exchanges ACH-000681\", \"Exchange & Intracellular A549\")\n",
    "data['input data'] = data['input data'].str.replace(\"fluxmapped activities\", \"Mapped Activities\").str.replace(\"activities\", \"Activities\")\n",
    "input_target_values = data['input data'] + '\\n->\\n' + data['target data']\n",
    "data['input target pair'] = input_target_values\n",
    "print(data['input target pair'].unique())\n",
    "filter = input_target_values.str.contains('|'.join(input_target_pairs))\n",
    "data = data.loc[filter].loc[data['method'] != 'GIMME'] \n",
    "data['method'] = data['method'].str.replace(\"LowMid\", \"Partial\").str.replace(\"HighMid\", \"Fixed\").str.replace(\"Reference Values\", \"Mid-bound Benchmark\")\n",
    "\n",
    "data = data.loc[~data['method'].str.contains('Scale') & ~data['method'].str.contains('Clip')]\n",
    "data = data.loc[~data['method'].str.contains('Scale') & ~data['method'].str.contains('Clip')]\n",
    "\n",
    "data['method'] = pd.Categorical(data['method'], \n",
    "                                [\"FBApro\", \n",
    "                                 \"FBAproPartial\", \n",
    "                                 \"FBAproFixed\",\n",
    "                                 \"FBA\",\n",
    "                                 \"MoMA\",\n",
    "                                 \"iMAT\",\n",
    "                                \"Mid-bound Benchmark\",\n",
    "                                ])\n",
    "\n",
    "# Create a multi-plot with two subplots, One for sample-based correlations and one for reaction-based correlations. Each one\n",
    "# will have a boxenplot with x as data y as correlation and hue as method.\n",
    "# sns.set_style('whitegrid')\n",
    "sns.set(style=\"darkgrid\", font_scale=2)\n",
    "g = sns.catplot(\n",
    "    data=data.loc[data['axis'] == 'sample'].sort_values(by=['method', 'input target pair']),\n",
    "    x=\"input target pair\",\n",
    "    y=\"correlation\",\n",
    "    hue=\"method\",\n",
    "    # col=\"axis\",\n",
    "    kind=\"bar\",\n",
    "    height=8,\n",
    "    aspect=1.5,\n",
    "    sharey=False\n",
    ")\n",
    "# g.set_axis_labels(\"Input Source -> Target Source\", \"Per-Sample Spearman Correlation\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Per-Sample Spearman Correlation\")\n",
    "# g.set_titles(col_template=\"Recon1 signed correlations\")\n",
    "# textwrap x tick labels, no rotation (remember it's a multiplot, do once per subplot)\n",
    "# for ax in g.axes.flat:\n",
    "#     labels = [textwrap.fill(label.get_text(), 15) for label in ax.get_xticklabels()]\n",
    "#     ax.set_xticklabels(labels)\n",
    "g._legend.set_title(\"Method\")\n",
    "g._legend.set_bbox_to_anchor((1.22, 0.7))\n",
    "plt.tight_layout()\n",
    "\n",
    "filename =  \"recon1_mapping.png\"\n",
    "g.savefig(os.path.join(export_path, filename))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a73161-6e59-49ac-8aa9-d64743c60038",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_target_values = full_correlation_df['input data'] + ', ' + full_correlation_df['target data']\n",
    "filter = input_target_values.str.contains('|'.join(input_target_pairs))\n",
    "plot_full_corrs(full_correlation_df.loc[filter], \"Recon1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
