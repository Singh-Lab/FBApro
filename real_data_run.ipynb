{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87713cef0a000c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cobra\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import projection_methods\n",
    "import torch\n",
    "import time\n",
    "from ge_processing import SampleNormalizationMethod, ArithmetizationMethod, process_full_ge, ge_to_reaction_activities\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up gurobi or other optimizer license file if needed\n",
    "# os.environ['GRB_LICENSE_FILE'] = \"/path/to/your/gurobi.lic\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "300ad48854b113af"
  },
  {
   "cell_type": "markdown",
   "id": "160266f744fb26a8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9195cd6269026b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cea800d19a08d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cobra.io.read_sbml_model(\"real_data_experiment_files/data/RECON1.xml\") # a metabolic model in sbml format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a7e9fb81d46c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(model.metabolites), len(model.reactions), len(model.genes), len(model.compartments)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flux data (NCI60 exchanges and intracellular fluxes for A549, MCF7)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b2c248bd732b4ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exchange_flux_data = pd.read_csv((\"real_data_experiment_files/data/nci60_exchange_data.csv\")).set_index('sample_id')\n",
    "# a csv with sample ids as index (agreeing with gene expression and intracellular data) and reaction ids as columns, plus one \"sample_id\" columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "699ccd325218439f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "intracellular_flux_data = pd.read_csv((\"real_data_experiment_files/data/intracellular_data.csv\")).set_index('sample_id')\n",
    "# a csv with sample ids as index (agreeing with gene expression and exchange data) and reaction ids as columns, plus one \"sample_id\" columns. \n",
    "\n",
    "# intracellular_flux_data = intracellular_flux_data.rename(columns={c: c.replace(\"_L(e)\", \"__L_e\") for c in intracellular_flux_data.columns}) # conversions specific to name formats in data and Recon1 model.\n",
    "\n",
    "print(\"intracellular #rxns: {}, #non-nan ACH-0000019: {}, # non-nan ACH-000682: {}, intersection: {}\".format(\n",
    "    len(intracellular_flux_data.columns), len(intracellular_flux_data.columns) - intracellular_flux_data.loc['ACH-000019'].isna().sum(),  len(intracellular_flux_data.columns) - intracellular_flux_data.loc['ACH-000681'].isna().sum(),\n",
    "     len(intracellular_flux_data.columns) - (intracellular_flux_data.isna().sum() >= 1).sum()\n",
    "))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d95bc6ae454da4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joint_intracellular_and_exchanges = pd.merge(intracellular_flux_data, exchange_flux_data.loc[intracellular_flux_data.index], left_index=True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f6c34b83a067066"
  },
  {
   "cell_type": "markdown",
   "id": "f09e89e0fd53cd22",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d23940ee8871f0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expression_data = pd.read_csv((\"real_data_experiment_files/data/ccle_gene_expression.csv\")).set_index('sample_id')\n",
    "# a csv file with a \"sample_id\" column, and the rest of the columns being ids of the model genes (up to a transcript variant separator suffix)\n",
    "expression_data = expression_data.loc[expression_data.index.isin(exchange_flux_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1f0763bfa91b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1028919669bcc11",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_transcript_variant_separator = \"_\"\n",
    "common_genes = set(expression_data.columns).intersection([g.id.split(gene_transcript_variant_separator)[0] for g in model.genes])\n",
    "len(expression_data.columns), len(model.genes), len(common_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22ebeedb935e5c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Convert expression to activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa388f2a6c2cc9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map expression_data columns to gene ids when there's a match with gene name\n",
    "expression_data = expression_data[expression_data.columns.intersection([g.id.split(gene_transcript_variant_separator)[0] for g in model.genes])]\n",
    "expression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expression_data.transpose().duplicated().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30a7bc94d82a61fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take mean of duplicated columns (replicas)\n",
    "expression_data = expression_data.groupby(expression_data.columns, axis=1).mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e78dbc00cc91dbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19ce08-57a9-46f0-9353-e3b999bfbefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_cache_path = \"real_data_experiment_files/caching/activities.csv\"\n",
    "model_suffix = \"_AT[0-9]+\" # a regex version of the gene suffix, to join different transcript variants of a gene\n",
    "\n",
    "if os.path.exists(activities_cache_path):\n",
    "    print(\"Loading activities from cache...\")\n",
    "    activities = pd.read_csv(activities_cache_path, index_col=0)\n",
    "else:\n",
    "    print(\"Computing activities...\")\n",
    "    activities = process_full_ge(model, expression_data, verbose=True, fixed_range_activities=True, model_suffix=model_suffix,\n",
    "                                 gene_zero_fraction_threshold=0.50, sample_normalization_method=SampleNormalizationMethod.quantile, post_processing_centering=False, arithmetization_mode=ArithmetizationMethod.arithmeangeomean)    \n",
    "    activities.to_csv(activities_cache_path)\n",
    "    print(f\"Activities saved to cache at {activities_cache_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2bcdfff1177e34",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activities_confident_indices = [i for i in range(len(activities.columns)) if not activities.iloc[:, i].isna().all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c79f59b59e0437",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"reactions with non-nan activity mapping: \", (activities.isna().sum(axis=0) == 0).sum(), \"/\", len(activities.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(activities.values.flatten())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3769a02a7ddc5b5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d8ff83168abcf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activities = (activities + 1) / 2\n",
    "# map an activity in range [0, 1] to the corresponding reaction's [lower_bound, upper_bound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424729dc3cee768",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assert all reactions are included\n",
    "assert (activities.columns == [r.id for r in model.reactions]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set model objective manually if desired (or if model has none)\n",
    "model_objective = \"S6T14g\"\n",
    "model.objective = model_objective\n",
    "# maximize sense\n",
    "model.objective.sense = 'max'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5899d19d307bd5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79da3131f2b299",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for r in model.reactions:\n",
    "#     r.bounds = (-1000, 1000)\n",
    "\n",
    "bounds_epsilon = 1e-5\n",
    "\n",
    "fva = cobra.flux_analysis.flux_variability_analysis(model,\n",
    "                                                   fraction_of_optimum=0.9,\n",
    "                                                   # pfba_factor=1.0,\n",
    "                                                    loopless=True)\n",
    "\n",
    "l_bounds_series = pd.Series(fva.minimum.to_numpy() - bounds_epsilon)\n",
    "u_bounds_series = pd.Series(fva.maximum.to_numpy() + bounds_epsilon)\n",
    "\n",
    "# duplicate per sample\n",
    "l_bounds = np.tile(fva.minimum.to_numpy() - bounds_epsilon, (len(activities), 1))\n",
    "u_bounds = np.tile(fva.maximum.to_numpy() + bounds_epsilon, (len(activities), 1))\n",
    "\n",
    "# convert to dataframe\n",
    "l_bounds = pd.DataFrame(index=activities.index, columns=[r.id for r in model.reactions],\n",
    "                        data=l_bounds)\n",
    "u_bounds = pd.DataFrame(index=activities.index, columns=[r.id for r in model.reactions],\n",
    "                        data=u_bounds)\n",
    "\n",
    "for r in model.reactions:\n",
    "    r.bounds = (fva.loc[r.id]['minimum'] - bounds_epsilon, fva.loc[r.id]['maximum'] + bounds_epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f50ebc53e689e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# m = model.copy()\n",
    "x=0\n",
    "for r in model.reactions:\n",
    "    if r.bounds[0] == 0 and r.bounds[1] == 0:\n",
    "        # print(r.id)\n",
    "        pass\n",
    "    if fva.loc[r.id]['minimum'] == 0 and fva.loc[r.id]['maximum'] == 0:\n",
    "        x += 1\n",
    "        # print(r.id)\n",
    "print(\"Blocked: {}/{}\".format(x, len(model.reactions)))\n",
    "# x = cobra.flux_analysis.flux_variability_analysis(model, fraction_of_optimum=0.1, pfba_factor=1.0)\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb35ed8d9b33a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# m = model.copy()\n",
    "x=0\n",
    "for r in model.reactions:\n",
    "    if r.bounds[0] == 0 and r.bounds[1] == 0:\n",
    "        # print(r.id)\n",
    "        pass\n",
    "    if fva.loc[r.id]['minimum'] == 0 and fva.loc[r.id]['maximum'] == 0:\n",
    "        if not activities[r.id].isna().all():\n",
    "            x += 1\n",
    "        # print(r.id)\n",
    "print(\"Blocked with activities: {}/ {}\".format(x, (activities.isna().sum(axis=0) == 0).sum()))\n",
    "# x = cobra.flux_analysis.flux_variability_analysis(model, fraction_of_optimum=0.1, pfba_factor=1.0)\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd846511f962257",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flux map\n",
    "fluxmapped_activities = activities.copy()\n",
    "assert (fluxmapped_activities.columns == [r.id for r in model.reactions]).all()\n",
    "bis = 0\n",
    "negs = 0\n",
    "pos = 0\n",
    "for i, r in enumerate(model.reactions):\n",
    "    lb = l_bounds_series[i]\n",
    "    ub = u_bounds_series[i]\n",
    "    if (lb < -bounds_epsilon) and (ub > bounds_epsilon):\n",
    "        fluxmapped_activities[r.id] = 0\n",
    "        bis += 1\n",
    "    else:\n",
    "        if ub < -bounds_epsilon:\n",
    "            # negative, reverse activity meaning\n",
    "            fluxmapped_activities[r.id] = fluxmapped_activities[r.id] * (lb - ub) + ub\n",
    "            negs += 1\n",
    "        else:\n",
    "            fluxmapped_activities[r.id] = fluxmapped_activities[r.id] * (ub - lb) + lb\n",
    "            pos += 1\n",
    "print(\"Negatives: {}, positives: {}, bidirectionals: {}\".format(negs, pos, bis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make directories if they don't exist in data_path\n",
    "export_path = \"real_data_experiment_files/outputs/recon1\"\n",
    "\n",
    "def export(df, path):\n",
    "    full_path = os.path.join(export_path, path)\n",
    "    os.makedirs(os.path.dirname(full_path), exist_ok=True)\n",
    "    df.to_csv(full_path)\n",
    "    \n",
    "# export activities, fluxmapped activities and flux_rates\n",
    "export(fluxmapped_activities, \"fluxes/fluxmapped_activities.csv\")\n",
    "export(exchange_flux_data, \"fluxes/NCI60_exchanges.csv\")\n",
    "for cell_line in intracellular_flux_data.index:\n",
    "    filtered_flux_df = intracellular_flux_data.loc[[cell_line]] \n",
    "    filtered_flux_df = filtered_flux_df.dropna(axis=1)\n",
    "    export(filtered_flux_df, \"fluxes/intracellular_{}.csv\".format(cell_line))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49fc6af3cdc3dd27"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction prep"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d650a376e794770"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "S = cobra.util.array.create_stoichiometric_matrix(model).astype(float)\n",
    "# projection = projection_methods.FbaProjectionLowMidConfidence(stoichiometric_matrix=S, unknown_indices=unknown_indices)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4369a7e3297642ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def full_apply(model, S, known_indices, filtered_flux_df, l_bounds, u_bounds):\n",
    "    if len(l_bounds.shape) == 1:\n",
    "        # duplicate per sample\n",
    "        l_bounds = np.tile(l_bounds.values, (len(filtered_flux_df), 1))\n",
    "        u_bounds = np.tile(u_bounds.values, (len(filtered_flux_df), 1))\n",
    "\n",
    "    unknown_indices = [i for i in range(len(model.reactions)) if i not in known_indices]\n",
    "\n",
    "    filtered_flux_df = filtered_flux_df.copy()\n",
    "    known_mat = np.zeros(shape=filtered_flux_df.shape, dtype=float)\n",
    "    known_mat[:, known_indices] = 1\n",
    "    mid_bounds = (l_bounds + u_bounds) / 2\n",
    "    filtered_flux_df.loc[:, :] = np.where(known_mat, filtered_flux_df, mid_bounds)\n",
    "\n",
    "    method_to_predictions = dict()\n",
    "    # for known_indices, set l_bounds and u_bounds with a -+100% gap from measured value\n",
    "    cur_l_bounds = l_bounds.copy()\n",
    "    cur_u_bounds = u_bounds.copy()\n",
    "    gap = abs(filtered_flux_df.iloc[:, known_indices]) * 1\n",
    "    cur_l_bounds[:, known_indices] = filtered_flux_df.iloc[:, known_indices] - gap\n",
    "    cur_u_bounds[:, known_indices] = filtered_flux_df.iloc[:, known_indices] + gap\n",
    "    for method in methods:\n",
    "        # try:\n",
    "        name = method.__repr__(None)\n",
    "        print(name)\n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "        start_time = time.time()\n",
    "        projection = (method(model=model, stoichiometric_matrix=S, unknown_indices=unknown_indices, \n",
    "                             measured_indices=known_indices, l_bounds=cur_l_bounds, \n",
    "                             u_bounds=cur_u_bounds, n_iters=10, objective_id=model_objective,\n",
    "                             acond=1e-5, rcond=1e-5,\n",
    "                             device=torch.device('cpu'), dtype=torch.float))\n",
    "                      #.to(dtype=float))\n",
    "        try:\n",
    "            projection = projection.to(dtype=float)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        predictions = projection.forward(torch.tensor(filtered_flux_df.values, dtype=float, device=torch.device('cpu')), l_bounds=cur_l_bounds, u_bounds=cur_u_bounds)\n",
    "        predictions = pd.DataFrame(index=filtered_flux_df.index, columns=[r.id for r in model.reactions], data=predictions.cpu().numpy())\n",
    "    \n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Time taken for {name}: {end_time - start_time:.2f} seconds\")\n",
    "        method_to_predictions[name] = predictions\n",
    "        # except Exception:\n",
    "        #     pass\n",
    "    return method_to_predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9efd873db947ab00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def leave_one_out_apply(model, S, known_indices, filtered_flux_df, l_bounds, u_bounds):\n",
    "    \n",
    "    if len(l_bounds.shape) == 1:\n",
    "        # duplicate per sample\n",
    "        l_bounds = np.tile(l_bounds.values, (len(filtered_flux_df), 1))\n",
    "        u_bounds = np.tile(u_bounds.values, (len(filtered_flux_df), 1))\n",
    "    \n",
    "    unknown_indices = [i for i in range(len(model.reactions)) if i not in known_indices]\n",
    "    # filtered_flux_df = filtered_flux_df.iloc[:4, :]\n",
    "    # l_bounds = l_bounds[:4]\n",
    "    # u_bounds = u_bounds[:4]\n",
    "\n",
    "    filtered_flux_df = filtered_flux_df.copy()\n",
    "    known_mat = np.zeros(shape=filtered_flux_df.shape, dtype=float)\n",
    "    known_mat[:, known_indices] = 1\n",
    "    mid_bounds = (l_bounds + u_bounds) / 2\n",
    "    filtered_flux_df.loc[:, :] = np.where(known_mat, filtered_flux_df, mid_bounds)\n",
    "\n",
    "    \n",
    "    method_to_predictions = dict()\n",
    "    for method in methods:\n",
    "        # try:\n",
    "        name = method.__repr__(None)\n",
    "        print(name)\n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "        start_time = time.time()\n",
    "        predictions = pd.DataFrame(index=filtered_flux_df.index, columns=[col for i, col in enumerate(model.reactions.list_attr('id')) if i in known_indices])    \n",
    "        if name == \"FBApro\": # can reuse the same projection matrix\n",
    "            projection = method(model=model, stoichiometric_matrix=S, device=torch.device('cpu'), dtype=torch.float, l_bounds=l_bounds, u_bounds=u_bounds,\n",
    "                               acond=1e-5, rcond=1e-5).to(dtype=float)\n",
    "        else:\n",
    "            projection = None\n",
    "            \n",
    "        for i, cur in enumerate(known_indices):\n",
    "            # if i >= 3:\n",
    "            #     continue\n",
    "            col = model.reactions[cur].id\n",
    "            held_out_reference_fluxes = filtered_flux_df.copy()\n",
    "            shape = held_out_reference_fluxes.shape\n",
    "            held_out_reference_fluxes.loc[:, col] = mid_bounds[:, cur] # 0\n",
    "            assert held_out_reference_fluxes.shape == shape\n",
    "            held_out_unknown_indices = unknown_indices.copy()\n",
    "            held_out_unknown_indices.append(cur)\n",
    "            held_out_known_indices = known_indices.copy()\n",
    "            held_out_known_indices.remove(cur)\n",
    "            # create context-specific l_bounds and u_bounds with -+100% gap on the measured value for each index in held_out_known_indices\n",
    "            cur_l_bounds = l_bounds.copy()\n",
    "            cur_u_bounds = u_bounds.copy()\n",
    "            for idx in held_out_known_indices:\n",
    "                gap = abs(held_out_reference_fluxes.iloc[:, idx]) * 1\n",
    "                cur_l_bounds[:, idx] = held_out_reference_fluxes.iloc[:, idx].values - gap\n",
    "                cur_u_bounds[:, idx] = held_out_reference_fluxes.iloc[:, idx].values + gap\n",
    "            if projection is None:\n",
    "                projection = method(model=model, stoichiometric_matrix=S, \n",
    "                                    unknown_indices=held_out_unknown_indices, \n",
    "                                    measured_indices=held_out_known_indices, \n",
    "                                    l_bounds=cur_l_bounds, u_bounds=cur_u_bounds, \n",
    "                                    n_iters=10, objective_id=model_objective,\n",
    "                                    acond=1e-3, rcond=1e-3,\n",
    "                                    device=torch.device('cpu'), dtype=torch.float)\n",
    "                try:\n",
    "                    projection = projection.to(dtype=float)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            res = projection.forward(torch.tensor(held_out_reference_fluxes.values, device=torch.device('cpu'), dtype=float), l_bounds=cur_l_bounds, u_bounds=cur_u_bounds)\n",
    "            predictions[col] = res.cpu().numpy()[:, cur]    \n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken for {name}: {end_time - start_time:.2f} seconds\")\n",
    "        method_to_predictions[name] = predictions\n",
    "        # except Exception as e:\n",
    "        #     print(\"Error running method {}\".format(method))\n",
    "        #     print(e)\n",
    "        #     pass\n",
    "    return method_to_predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d3e9abc91e4ea6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exchange fluxes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdd59131e6a9e65d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Leave-one-out flux predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77ead528d63b7be1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2169fc03dc0b9b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "methods = [\n",
    "    projection_methods.FBAWrapper,\n",
    "    projection_methods.FbaProjection, \n",
    "    projection_methods.FbaProjectionLowMidConfidence,\n",
    "    projection_methods.FbaProjectionHighMidConfidence,\n",
    "    projection_methods.IMATWrapper,\n",
    "    projection_methods.MoMAWrapper\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6f1a7c3932d7dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_flux_df = exchange_flux_data\n",
    "reference_fluxes = torch.zeros((len(filtered_flux_df.index), len(model.reactions)), dtype=torch.float32, device='cpu')\n",
    "known_indices = []\n",
    "for i, r in enumerate(model.reactions.list_attr('id')):\n",
    "    if \"EX_\" in r:\n",
    "        reaction = model.reactions.get_by_id(r)\n",
    "        # print(r, len(reaction.reactants), len(reaction.products))\n",
    "        # for m in reaction.metabolites:\n",
    "        #     if reaction.get_coefficient(m) != -1:\n",
    "        #         print(reaction.get_coefficient(m))\n",
    "        # try to find the \"_c\" version of r in the intracellular rates\n",
    "        if r in filtered_flux_df.columns:\n",
    "            # take the mean of the fluxes across all time points\n",
    "            reference_fluxes[:, i] = torch.tensor(filtered_flux_df[r].values)\n",
    "            known_indices.append(i)\n",
    "        else:\n",
    "            reference_fluxes[:, i] = 0\n",
    "    else:\n",
    "        reference_fluxes[:, i] = 0\n",
    "# make reference_fluxes into a df\n",
    "reference_fluxes = pd.DataFrame(index=filtered_flux_df.index, columns=[r.id for r in model.reactions], data=reference_fluxes.cpu().numpy())\n",
    "all_reference_fluxes = reference_fluxes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f6626b3ab758284"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "method_to_predictions = leave_one_out_apply(model, S, known_indices, reference_fluxes, l_bounds_series, u_bounds_series)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7939d7bf21eb8546"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "141b97e35d0f6f54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bfa4f78b35b208",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for method_name, predictions in method_to_predictions.items():\n",
    "    export(predictions, \"predictions/leave_one_out/NCI60_exchanges/{}.csv\".format(method_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39b7250f21543a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Intracellular fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509e3d99d71150c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Leave-one-out flux predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d2422f3c2a37a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    projection_methods.FBAWrapper,\n",
    "    projection_methods.FbaProjection, \n",
    "    projection_methods.FbaProjectionLowMidConfidence,\n",
    "    projection_methods.FbaProjectionHighMidConfidence,\n",
    "    projection_methods.IMATWrapper,\n",
    "    projection_methods.MoMAWrapper\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356b3bb0351ab3f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cell_line in intracellular_flux_data.index:\n",
    "    filtered_flux_df = intracellular_flux_data.loc[[cell_line]] \n",
    "    filtered_flux_df = filtered_flux_df.dropna(axis=1)\n",
    "    reference_fluxes = torch.zeros((len(filtered_flux_df.index), len(model.reactions)), dtype=torch.float32, device='cpu')\n",
    "    known_indices = []\n",
    "    for i, r in enumerate(model.reactions.list_attr('id')):\n",
    "        reaction = model.reactions.get_by_id(r)\n",
    "        # print(r, len(reaction.reactants), len(reaction.products))\n",
    "        # for m in reaction.metabolites:\n",
    "        #     if reaction.get_coefficient(m) != -1:\n",
    "        #         print(reaction.get_coefficient(m))\n",
    "        # try to find the \"_c\" version of r in the intracellular rates\n",
    "        if r in filtered_flux_df.columns:\n",
    "            # take the mean of the fluxes across all time points\n",
    "            reference_fluxes[:, i] = torch.tensor(filtered_flux_df[r].values)\n",
    "            known_indices.append(i)\n",
    "        else:\n",
    "            reference_fluxes[:, i] = 0\n",
    "    # make reference_fluxes into a df\n",
    "    reference_fluxes = pd.DataFrame(index=filtered_flux_df.index, columns=[r.id for r in model.reactions], data=reference_fluxes.cpu().numpy())\n",
    "    \n",
    "    method_to_predictions = leave_one_out_apply(model, S, known_indices, reference_fluxes.fillna(0), l_bounds_series, u_bounds_series)\n",
    "    \n",
    "    for method_name, predictions in method_to_predictions.items():\n",
    "        export(predictions, \"predictions/leave_one_out/intracellular_{}/{}.csv\".format(cell_line, method_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474dcf1-977e-4b31-a12e-59fcdbbd4923",
   "metadata": {},
   "source": [
    "# Intracellular fluxes + NCI60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec6db0-ad7d-4c76-89d7-b59814bbb4a8",
   "metadata": {},
   "source": [
    "## Leave-one-out flux predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be371e0-0e6d-470b-8c5a-b77f41873f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    projection_methods.FBAWrapper,\n",
    "    projection_methods.FbaProjection, \n",
    "    projection_methods.FbaProjectionLowMidConfidence,\n",
    "    projection_methods.FbaProjectionHighMidConfidence,\n",
    "    projection_methods.IMATWrapper,\n",
    "    projection_methods.MoMAWrapper\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eda6cc-1361-4c36-af1f-ab8e36ea79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_line in joint_intracellular_and_exchanges.index:\n",
    "    filtered_flux_df = joint_intracellular_and_exchanges.loc[[cell_line]] \n",
    "    filtered_flux_df = filtered_flux_df.dropna(axis=1)\n",
    "    reference_fluxes = torch.zeros((len(filtered_flux_df.index), len(model.reactions)), dtype=torch.float32, device='cpu')\n",
    "    known_indices = []\n",
    "    for i, r in enumerate(model.reactions.list_attr('id')):\n",
    "        reaction = model.reactions.get_by_id(r)\n",
    "        # print(r, len(reaction.reactants), len(reaction.products))\n",
    "        # for m in reaction.metabolites:\n",
    "        #     if reaction.get_coefficient(m) != -1:\n",
    "        #         print(reaction.get_coefficient(m))\n",
    "        # try to find the \"_c\" version of r in the intracellular rates\n",
    "        if r in filtered_flux_df.columns:\n",
    "            # take the mean of the fluxes across all time points\n",
    "            reference_fluxes[:, i] = torch.tensor(filtered_flux_df[r].values)\n",
    "            known_indices.append(i)\n",
    "        else:\n",
    "            reference_fluxes[:, i] = 0\n",
    "    # make reference_fluxes into a df\n",
    "    reference_fluxes = pd.DataFrame(index=filtered_flux_df.index, columns=[r.id for r in model.reactions], data=reference_fluxes.cpu().numpy())\n",
    "    \n",
    "    method_to_predictions = leave_one_out_apply(model, S, known_indices, reference_fluxes.fillna(0), l_bounds_series, u_bounds_series)\n",
    "    \n",
    "    for method_name, predictions in method_to_predictions.items():\n",
    "        export(predictions, \"predictions/leave_one_out/joint_intracellular_and_exchanges_{}/{}.csv\".format(cell_line, method_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a71a1f9c60ef62",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fluxmapped-GE based predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c64fcb1928450c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b494f1379e88e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db726aa41ae32a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    projection_methods.FBAWrapper,\n",
    "    projection_methods.FbaProjection, \n",
    "    projection_methods.FbaProjectionLowMidConfidence,\n",
    "    projection_methods.FbaProjectionHighMidConfidence,\n",
    "    projection_methods.RawInputWrapper,\n",
    "    projection_methods.IMATWrapper,\n",
    "    projection_methods.MoMAWrapper\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057e489b66f269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_fluxes = fluxmapped_activities\n",
    "\n",
    "method_to_predictions = full_apply(model, S, activities_confident_indices, reference_fluxes, l_bounds_series, u_bounds_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2169256404facfe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Export predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc157b91dda519e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Export predictions\n",
    "for method_name, predictions in method_to_predictions.items():\n",
    "    export(predictions, \"predictions/full/fluxmapped_activities/{}.csv\".format(method_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
